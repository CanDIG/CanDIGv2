{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CanDIGv2 Services Demo\n",
    "- - -\n",
    "\n",
    "This notebook outlines how to use the demonstration server and client to make a simple Data Object service that makes available data from a few different sources using CanDIGv2. The CanDIGv2 project is a collection of heterogeneos services designed to work together to facilitate end to end dataflow for genomic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Topology\n",
    "\n",
    "```\n",
    "+---------------------------------------------------------------------------------------------+\n",
    "|                                                                                             |\n",
    "|                                    +--------------+                                         |\n",
    "|                                    | candig.local |                                         |\n",
    "|                                    +--------------+                                         |\n",
    "|                                            |                                                |\n",
    "|                                            |                                                |\n",
    "|                                            |                 +------------------------+     |\n",
    "|                                 +--------------------+       | consul:8300-8310 (tcp) |     |\n",
    "|   +-----------------------+     | traefik:8000 (tcp) |       |       :8400      (tcp) |     |\n",
    "|   | weavescope:4040 (tcp) |-----|        :80   (tcp) |-------|       :8500      (tcp) |     |\n",
    "|   +-----------------------+     |        :443  (tcp) |       |       :8301-8302 (udp) |     |\n",
    "|                                 +--------------------+       |       :8600      (udp) |     |\n",
    "|                                            |                 +------------------------+     |\n",
    "|                                            |                                                |\n",
    "|                                            |                                                |\n",
    "|       +-------------------+     +--------------------+       +----------------------+       |\n",
    "|       | htsget:4844 (tcp) |-----| jupyter:8888 (tcp) |-------| ga4gh-dos:8080 (tcp) |       |\n",
    "|       +-------------------+     +--------------------+       +----------------------+       |\n",
    "|                                            |                                                |\n",
    "|                                            |                                                |\n",
    "|                                            |                                                |\n",
    "|                                            |                                                |\n",
    "|        +----------------------+            |          +----------------------------------+  |\n",
    "|        | +------------------+ |            |          | +------------------------------+ |  |\n",
    "|        | | minio:9000 (tcp) | |            |          | |  toil-master/wes:5050 (tcp)  | |  |\n",
    "|        | +------------------+ |            |          | +------------------------------+ |  |\n",
    "|        | +------------------+ |------------+----------| +------------------------------+ |  |\n",
    "|        | |minio-client (mc) | |                       | |   toil-worker:5051 (tcp)     | |  |\n",
    "|        | +------------------+ |                       | +------------------------------+ |  |\n",
    "|        +----------------------+                       +----------------------------------+  |\n",
    "|                                                                                             |\n",
    "+---------------------------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "If you are starting from a blank jupyter-lab instance, you won't have the ipython kernel needed for CanDIGv2. So let's create it. Copy/paste the following code into your **bash** shell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /notebooks/demo/CanDIGv2\n",
    "\n",
    "conda env create -f etc/conda/environment.yml\n",
    "conda activate candig\n",
    "python -m ipykernel install --user --name candig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be nice to keep a `bash` shell running along with out `iPyKernel`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Minio Object Store with Buckets and Data\n",
    "\n",
    "We will need minio server/client with some demo data before we continue. Normally this is something we can do easily when using CanDIGv2 in `Swarm` or `Kubernetes` mode, but for a local `Compose` demo we need to take some extra steps.\n",
    "\n",
    "First, we need to copy over the `minio_acess_key` and `minio-secret-key` from our host. Copy/paste into the corresponding files or just run the following docker commands from the **host machine** with the keys:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_container=$(docker ps | grep jupyter | awk '{print $1}')\n",
    "docker cp minio-access-key $jp_container:/notebooks/demo/CanDIGv2/\n",
    "docker cp minio-secret-key $jp_container:/notebooks/demo/CanDIGv2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets get the latest minio client in our env:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/demo/CanDIGv2\n"
     ]
    }
   ],
   "source": [
    "# check we are in the project root directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir -p /notebooks/demo/CanDIGv2/bin\n",
      "curl -Lo /notebooks/demo/CanDIGv2/bin/minio \\\n",
      "\thttps://dl.minio.io/server/minio/release/linux-amd64/minio\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 40.7M  100 40.7M    0     0  2518k      0  0:00:16  0:00:16 --:--:-- 3223k\n",
      "curl -Lo /notebooks/demo/CanDIGv2/bin/mc \\\n",
      "\thttps://dl.minio.io/client/mc/release/linux-amd64/mc\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 16.0M  100 16.0M    0     0  1835k      0  0:00:08  0:00:08 --:--:-- 2046k\n",
      "chmod 755 /notebooks/demo/CanDIGv2/bin/minio\n",
      "chmod 755 /notebooks/demo/CanDIGv2/bin/mc\n"
     ]
    }
   ],
   "source": [
    "# copy over a site.env for compose testing\n",
    "!cp $(pwd)/etc/site/compose.env $(pwd)/site.env\n",
    "\n",
    "!make minio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run this script to populate our Minio Object Store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32mAdded `minio` successfully.\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!bin/mc config host add minio http://minio:9000 $(cat minio-access-key) $(cat minio-secret-key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘NA20276.mapped.ILLUMINA.bwa.ASW.low_coverage.20120522.bam’ already there; not retrieving.\n",
      "\n",
      "File ‘chr22.fa.gz’ already there; not retrieving.\n",
      "\n",
      "\u001b[m\u001b[32;1mBucket created successfully `minio/candig/hg38/chromosomes/`.\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32;1mBucket created successfully `minio/candig/1000genomes/phase3/data/NA20276/alignment/`.\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32;1mBucket created successfully `minio/candig/reads/BroadHiSeqX_b37/NA12878/`.\u001b[0m\n",
      "chr22.fa.gz:   11.69 MiB / 11.69 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 100.00% 37.89 MiB/s 0s\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!wget -nc --continue https://s3.amazonaws.com/1000genomes/phase3/data/NA20276/alignment/NA20276.mapped.ILLUMINA.bwa.ASW.low_coverage.20120522.bam\n",
    "!wget -nc --continue http://hgdownload.cse.ucsc.edu/goldenPath/hg38/chromosomes/chr22.fa.gz\n",
    "#!wget -nc --continue https://dl.dnanex.us/F/D/Pb1QjgQx9j2bZ8Q44x50xf4fQV3YZBgkvkz23FFB/NA12878_recompressed.bam\n",
    "\n",
    "!bin/mc mb minio/candig/hg38/chromosomes/\n",
    "!bin/mc mb minio/candig/1000genomes/phase3/data/NA20276/alignment/\n",
    "!bin/mc mb minio/candig/reads/BroadHiSeqX_b37/NA12878/\n",
    "\n",
    "!bin/mc cp NA20276.mapped.ILLUMINA.bwa.ASW.low_coverage.20120522.bam minio/candig/1000genomes/phase3/data/NA20276/alignment/\n",
    "!bin/mc cp chr22.fa.gz minio/candig/hg38/chromosomes/\n",
    "#!bin/mc cp NA12878_recompressed.bam minio/candig/reads/BroadHiSeqX_b37/NA12878/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with DOS/DRS API\n",
    "\n",
    "A useful Data Object Service might present a list of available reference FASTAs for performing downstream alignment and analysis.\n",
    "\n",
    "We'll index the UCSC human reference FASTAs into DOS as an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, json\n",
    "import datetime\n",
    "\n",
    "d = datetime.datetime.utcnow()\n",
    "\n",
    "headers = {'content-type': 'application/json'}\n",
    "url = 'http://ga4gh-dos:8080/ga4gh/dos/v1/dataobjects'\n",
    "data = json.dumps({\"data_object\": {\"id\": \"hg38-chr22\",\n",
    "     \"name\": \"Human Reference Chromosome 22\",\n",
    "     \"created\": d.isoformat(\"T\") + \"Z\",\n",
    "     \"checksums\": [{\"checksum\": \"41b47ce1cc21b558409c19b892e1c0d1\", \"type\": \"md5\"}],\n",
    "     \"urls\": [{\"url\": \"http://minio:9000/candig/hg38/chromosomes/chr22.fa.gz\"}],\n",
    "     \"size\": \"12255678\"}})\n",
    "\n",
    "requests.post(url, data, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_objects\": [\n",
      "    {\n",
      "      \"checksums\": [\n",
      "        {\n",
      "          \"checksum\": \"41b47ce1cc21b558409c19b892e1c0d1\",\n",
      "          \"type\": \"md5\"\n",
      "        }\n",
      "      ],\n",
      "      \"created\": \"2019-05-28T18:38:16.960271Z\",\n",
      "      \"id\": \"hg38-chr22\",\n",
      "      \"name\": \"Human Reference Chromosome 22\",\n",
      "      \"size\": \"12255678\",\n",
      "      \"updated\": \"2019-05-28T18:38:16.960285Z\",\n",
      "      \"urls\": [\n",
      "        {\n",
      "          \"url\": \"http://minio:9000/candig/hg38/chromosomes/chr22.fa.gz\"\n",
      "        }\n",
      "      ],\n",
      "      \"version\": \"2019-05-28T18:38:16.960291Z\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(url)\n",
    "\n",
    "print r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Client to Access the Demo Server\n",
    "\n",
    "We can now use the Python client to create a simple Data Object. The same could be done using cURL or wget but we want to be more programmatic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ga4gh.dos.client import Client\n",
    "\n",
    "client = Client(\"http://ga4gh-dos:8080/ga4gh/dos/v1\")\n",
    "c = client.client\n",
    "models = client.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Data Objects\n",
    "\n",
    "To list the existing Data Objects, we send a `ListDataObjectsRequest` to the ListDataObjects method!\n",
    "\n",
    "**NOTE:** If you install ga4gh-dos-schema via pip, there is a dependency error with the `ga4gh.dos.client` library. Run the following command to fix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonschema==2.6.0\n",
      "  Using cached https://files.pythonhosted.org/packages/77/de/47e35a97b2b05c2fadbec67d44cfcdcd09b8086951b331d82de90d2912da/jsonschema-2.6.0-py2.py3-none-any.whl\n",
      "Installing collected packages: jsonschema\n",
      "  Found existing installation: jsonschema 3.0.1\n",
      "    Uninstalling jsonschema-3.0.1:\n",
      "      Successfully uninstalled jsonschema-3.0.1\n",
      "Successfully installed jsonschema-2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Dependency mapping issues - https://github.com/ga4gh/data-repository-service-schemas/issues/147\n",
    "!pip install jsonschema==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data Objects: 3 \n"
     ]
    }
   ],
   "source": [
    "# FIXED :)\n",
    "ListDataObjectsRequest = models.get_model('ListDataObjectsRequest')\n",
    "list_request = c.ListDataObjects(page_size=10000000)\n",
    "list_response = list_request.result()\n",
    "print(\"Number of Data Objects: {} \".format(len(list_response.data_objects)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the DataObject in order to retrieve just the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: http://minio:9000/candig/hg38/chromosomes/chr22.fa.gz, file_size (B): 12255678\n"
     ]
    }
   ],
   "source": [
    "# FIXED :)\n",
    "data_objects = list_response.data_objects\n",
    "data_object = data_objects[1]\n",
    "print('url: {}, file_size (B): {}'.format(data_object.urls[0].url, data_object.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are additional features of the DOS client, such as querying against public DOS/DRS instaces and working with DataBundles, but this is out of scope of our demo. You can review these topics [here](https://github.com/ga4gh/data-repository-service-schemas/blob/master/python/examples/gdc_notebook.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DOS with htsget\n",
    "\n",
    "Data Objects are meant to represent versioned artifacts and can represent an API resource. For example, we could use DOS as a way of exposing htsget resources.\n",
    "\n",
    "In the [htsget Quickstart documentation](https://htsget.readthedocs.io/en/stable/quickstart.html) a link is made to the following snippet, which will stream the BAM results to the client.\n",
    "\n",
    "In this example, we will take a subset of the Illumina Platinum Genomes NA12878 and create a DataObject with metadata corresponding to the genomic range of interest. Using `htsget` is useful in cases such as this, since BAM files can be VERY large..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spider mode enabled. Check if remote file exists.\n",
      "--2019-05-29 07:27:25--  https://dl.dnanex.us/F/D/Pb1QjgQx9j2bZ8Q44x50xf4fQV3YZBgkvkz23FFB/NA12878_recompressed.bam\n",
      "Resolving dl.dnanex.us (dl.dnanex.us)... 3.89.79.27, 54.164.161.183\n",
      "Connecting to dl.dnanex.us (dl.dnanex.us)|3.89.79.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 140786687556 (131G) [application/x-gzip]\n",
      "Remote file exists.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --spider https://dl.dnanex.us/F/D/Pb1QjgQx9j2bZ8Q44x50xf4fQV3YZBgkvkz23FFB/NA12878_recompressed.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular sequence file is **131GB *compressed***, way too large to download over hotel/conference wi-fi. Furthermore, we do not need the entire dataset for our use case. So let's slice it with `htsget` and create a DataObject that we can use for downstream analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GetDataObjectResponse(data_object=DataObject(aliases=[u'NA12878 chr 2 subset'], checksums=[Checksum(checksum=u'eaf80af5e9e54db5936578bed06ffcdc', type=u'md5')], created=datetime.datetime(2019, 5, 28, 22, 12, 4, 831951, tzinfo=tzlocal()), description=None, id=u'na12878_2', mime_type=None, name=u'NA12878_2.bam', size=555749, updated=datetime.datetime(2019, 5, 28, 22, 12, 4, 831960, tzinfo=tzlocal()), urls=[URL(system_metadata=SystemMetadata(end=20000, reference_name=2, start=1000), url=u'http://minio:9000/candig/reads/BroadHiSeqX_b37/NA12878', user_metadata=None)], version=u'2019-05-28T22:12:04.831964Z'))\n"
     ]
    }
   ],
   "source": [
    "from ga4gh.dos.client import Client\n",
    "import htsget\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# https://stackoverflow.com/questions/8556398/generate-rfc-3339-timestamp-in-python#8556555\n",
    "d = datetime.datetime.utcnow()\n",
    "d_with_timezone = d.replace(tzinfo=pytz.UTC)\n",
    "\n",
    "# htsget docs - https://htsget.readthedocs.io/en/latest/quickstart.html\n",
    "url = \"http://htsnexus.rnd.dnanex.us/v1/reads/BroadHiSeqX_b37/NA12878\"\n",
    "with open(\"NA12878_2.bam\", \"wb\") as output:\n",
    "    htsget.get(url, output, reference_name=\"2\", start=1000, end=20000)\n",
    "\n",
    "# https://github.com/ga4gh/data-repository-service-schemas/blob/master/python/examples/object-type-examples.ipynb\n",
    "client = Client(\"http://ga4gh-dos:8080/ga4gh/dos/v1/\")\n",
    "c = client.client\n",
    "models = client.models\n",
    "\n",
    "DataObject = models.get_model('DataObject')\n",
    "Checksum = models.get_model('Checksum')\n",
    "URL = models.get_model('URL')\n",
    "\n",
    "na12878_2 = DataObject()\n",
    "na12878_2.id = 'na12878_2'\n",
    "na12878_2.name = 'NA12878_2.bam'\n",
    "na12878_2.checksums = [\n",
    "    Checksum(checksum='eaf80af5e9e54db5936578bed06ffcdc', type='md5')]\n",
    "na12878_2.urls = [\n",
    "    URL(\n",
    "        url=\"http://minio:9000/candig/reads/BroadHiSeqX_b37/NA12878\",\n",
    "        system_metadata={'reference_name': 2, 'start': 1000, 'end': 20000})]\n",
    "na12878_2.aliases = ['NA12878 chr 2 subset']\n",
    "na12878_2.size = '555749'\n",
    "na12878_2.created = d_with_timezone\n",
    "\n",
    "c.CreateDataObject(body={'data_object': na12878_2}).result()\n",
    "\n",
    "response = c.GetDataObject(data_object_id='na12878_2').result()\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will place this file back into our minio-server to so that others can retrieve this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...878_2.bam:  542.72 KiB / 542.72 KiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 100.00% 27.02 MiB/s 0s\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!bin/mc cp NA12878_2.bam minio/candig/reads/BroadHiSeqX_b37/NA12878/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DOS with WES\n",
    "\n",
    "The Workflow Execution Service attempts to present the interface for workflow execution over HTTP methods. Simple JSON requests including the inputs and outputs for a workflow are sent to a service. This allows us to \"ship code to the data,\" since data privacy and egress costs require that data is not shared.\n",
    "\n",
    "UCSC Toil is software for executing workflows. It presents a Python native API, which will not be demonstrated here, as well as a CWL compliant CLI interface. For that reason, any CWLRunner can easily be exposed by the workflow-service, demonstrated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wes-server --backend=wes_service.cwl_runner --opt runner=cwltoil --opt extra=--logLevel=CRITICAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background processes aren't supported directly in notebooks, so we close it here. But you can paste this command in a terminal and it will bring up your very own Workflow Execution Service!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Client\n",
    "\n",
    "The server is now running, but Toil hasn't started yet as we haven't issued any Workflow Execution requests. Here, using the provided CLI client, we demonstrate a simple workflow which calculates an md5sum.\n",
    "\n",
    "### Accessing a workflow via Dockstore Tool Registry Service\n",
    "\n",
    "We will start by accessing the metadata for a workflow from dockstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'descriptor_type': [u'CWL', u'WDL'], u'verified': True, u'name': u'master', u'url': u'https://dockstore.org/api/api/ga4gh/v2/tools/quay.io%2Fbriandoconnor%2Fdockstore-tool-md5sum/versions/master', u'image': u'7f82fc51fa35d36bbd61297ee0c05170ab4ba67c969a9a66b28e5ed3c100034b', u'verified_source': u'Phase 1 GA4GH Tool Execution Challenge', u'image_name': u'quay.io/briandoconnor/dockstore-tool-md5sum', u'meta_version': u'2017-07-23 15:45:37.0', u'id': u'quay.io/briandoconnor/dockstore-tool-md5sum:master', u'containerfile': True, u'registry_url': u'quay.io'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('https://dockstore.org:8443/api/ga4gh/v2/tools/', params={\"name\": \"md5sum\"})\n",
    "print(response.json()[0]['versions'][7])\n",
    "md5sum_url = response.json()[0]['versions'][7]['url'] + '/plain-CWL/descriptor/%2FDockstore.cwl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a URL we can pass too WES for execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dockstore.org/api/api/ga4gh/v2/tools/quay.io%2Fbriandoconnor%2Fdockstore-tool-md5sum/versions/master/plain-CWL/descriptor/%2FDockstore.cwl\n"
     ]
    }
   ],
   "source": [
    "print(md5sum_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the WES CLI client to Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'workflow-service'...\n",
      "remote: Enumerating objects: 101, done.\u001b[K\n",
      "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
      "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
      "remote: Total 1105 (delta 55), reused 67 (delta 33), pack-reused 1004\u001b[K\n",
      "Receiving objects: 100% (1105/1105), 260.72 KiB | 970.00 KiB/s, done.\n",
      "Resolving deltas: 100% (629/629), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/common-workflow-language/workflow-service.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wes-client --host 172.16.47.156:8181 --proto http $md5sum_url workflow-service/testdata/md5sum.cwl.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the wes-client routed a request and polled the service until the its state was `COMPLETE`. It then shows us the location of the outputs, so we can read them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Workflows Against Remote WES Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...kflow.cwl:  76.96 MiB / 76.96 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 100.00% 397.92 MiB/s 0s\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!mkdir -p demo\n",
    "!bin/mc cp --recursive minio/candig/wes/workflows/demo/ demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cwltool:Resolved 'demo/workflow.cwl' to 'file:///notebooks/demo/CanDIGv2/demo/workflow.cwl'\n",
      "WARNING:toil.batchSystems.singleMachine:Limiting maxMemory to physically available memory (16709406720).\n",
      "WARNING:toil.batchSystems.singleMachine:Limiting maxDisk to physically available disk (40889761792).\n",
      "ERROR:pymesos.process:Failed to process event\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/process.py\", line 194, in read\n",
      "    self._callback.process_event(event)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/process.py\", line 274, in process_event\n",
      "    self.on_event(event)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/scheduler.py\", line 641, in on_event\n",
      "    func(event)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/scheduler.py\", line 559, in on_offers\n",
      "    self, [self._dict_cls(offer) for offer in offers]\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/toil/batchSystems/mesos/batchSystem.py\", line 423, in resourceOffers\n",
      "    self._trackOfferedNodes(offers)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/toil/batchSystems/mesos/batchSystem.py\", line 508, in _trackOfferedNodes\n",
      "    assert(offer.agent_id.has_key('value'))\n",
      "TypeError: 'Dict' object is not callable\n",
      "ERROR:pymesos.process:Thread abort:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/process.py\", line 372, in _run\n",
      "    if not conn.read():\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/process.py\", line 194, in read\n",
      "    self._callback.process_event(event)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/process.py\", line 274, in process_event\n",
      "    self.on_event(event)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/scheduler.py\", line 641, in on_event\n",
      "    func(event)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/scheduler.py\", line 559, in on_offers\n",
      "    self, [self._dict_cls(offer) for offer in offers]\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/toil/batchSystems/mesos/batchSystem.py\", line 423, in resourceOffers\n",
      "    self._trackOfferedNodes(offers)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/toil/batchSystems/mesos/batchSystem.py\", line 508, in _trackOfferedNodes\n",
      "    assert(offer.agent_id.has_key('value'))\n",
      "TypeError: 'Dict' object is not callable\n",
      "INFO:toil.common:Successfully deleted the job store: FileJobStore(/tmp/tmpfxi323kx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/toil-cwl-runner\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/toil/cwl/cwltoil.py\", line 1276, in main\n",
      "    outobj = toil.start(wf1)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/toil/common.py\", line 781, in start\n",
      "    return self._runMainLoop(rootJobGraph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/toil/common.py\", line 1043, in _runMainLoop\n",
      "    logProcessContext(self.config)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/toil/__init__.py\", line 417, in logProcessContext\n",
      "    log.info(\"Running Toil version %s.\", version)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 1308, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 1444, in _log\n",
      "    self.handle(record)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 1454, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 1516, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 863, in handle\n",
      "    self.acquire()\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 814, in acquire\n",
      "    self.lock.acquire()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/process.py\", line 37, in _handle_sigint\n",
      "    reraise(*exc_info)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/six.py\", line 693, in reraise\n",
      "    raise value\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/process.py\", line 372, in _run\n",
      "    if not conn.read():\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/process.py\", line 194, in read\n",
      "    self._callback.process_event(event)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/process.py\", line 274, in process_event\n",
      "    self.on_event(event)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/scheduler.py\", line 641, in on_event\n",
      "    func(event)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pymesos/scheduler.py\", line 559, in on_offers\n",
      "    self, [self._dict_cls(offer) for offer in offers]\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/toil/batchSystems/mesos/batchSystem.py\", line 423, in resourceOffers\n",
      "    self._trackOfferedNodes(offers)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/toil/batchSystems/mesos/batchSystem.py\", line 508, in _trackOfferedNodes\n",
      "    assert(offer.agent_id.has_key('value'))\n",
      "TypeError: 'Dict' object is not callable\n"
     ]
    }
   ],
   "source": [
    "!toil-cwl-runner --clean onError --cleanWorkDir onError --batchSystem mesos --mesosMaster toil-master:5050 demo/workflow.cwl demo/inputs.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "candig",
   "language": "python",
   "name": "candig"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
